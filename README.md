# Project Summary

1. Apply transformations to flight delays data using **spark-sql**
  ..* Upload csv or json data files into Bigquery partition tables from bucket
  ..* Create dataproc cluster 
  ..* Add actions like **Zookeeper** , **Kafka** and **Jupyter Notebook** to the cluster
  4. Use jupyter notebook to transform the data using various spark sql query
2. Save the transformed data into Google **Bigquery** partitioned tables
3. Use **Google workflow** templates to automate the spark **ETL** batch processing jobs.
4. Use **Apache Airflow** to create DAG & automate batch processin

