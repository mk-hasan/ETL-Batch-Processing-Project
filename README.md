# Project Summary

1. Apply transformations to flight delays data using **spark-sql**
  1. Upload csv or json data files into Bigquery partition tables from bucket
  2. Create dataproc cluster 
  3. Add actions like *Zookeeper* , *Kafka* and *Jupyter Notebook* to the cluster
  4. Use jupyter notebook to transform the data using various spark sql query
2. Save the transformed data into Google **Bigquery** partitioned tables
3. Use **Google workflow** templates to automate the spark **ETL** batch processing jobs.
4. Use **Apache Airflow** to create DAG & automate batch processin

